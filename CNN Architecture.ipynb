{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is the role of filters and feature maps in Convolutional\n",
        "Neural Network (CNN)?\n",
        "\n",
        "Answer : Filters (kernels) are small matrices that slide across the input image to detect specific features such\n",
        "as edges, textures, or patterns. Each filter produces a feature map, which highlights the presence\n",
        "and location of those learned features in the input. Together, multiple filters enable CNNs to learn\n",
        "hierarchical feature representations, where shallow layers detect simple patterns and deeper layers\n",
        "capture complex structures\n",
        "\n",
        "Question 2: Explain the concepts of padding and stride in CNNs. How do\n",
        "they affect the output dimensions of feature maps?\n",
        "\n",
        "Answer : Padding involves adding extra pixels (usually zeros) around the input image to preserve spatial\n",
        "dimensions after convolution. Without padding, feature maps shrink as convolution is applied.\n",
        "Stride refers to the step size of the filter while moving across the image. A larger stride reduces the\n",
        "output size, while a stride of 1 retains more spatial detail. Together, padding and stride control the\n",
        "resolution of the feature maps.\n",
        "\n",
        "Question 3: Define receptive field in the context of CNNs. Why is it important\n",
        "for deep architectures?\n",
        "\n",
        "Answer : The receptive field refers to the region of the input image that a particular neuron in a CNN layer is\n",
        "sensitive to. As we go deeper in the network, the receptive field grows, allowing neurons to capture\n",
        "broader context and complex dependencies. This is crucial in deep architectures because it\n",
        "enables higher-level understanding of global patterns, such as shapes or objects, rather than just\n",
        "local edges.\n",
        "\n",
        "Question 4: Discuss how filter size and stride influence the number of\n",
        "parameters in a CNN.\n",
        "\n",
        "Answer : Filter size directly impacts the number of trainable parameters: larger filters require more weights,\n",
        "increasing model complexity. Stride, however, does not change the number of parameters but\n",
        "affects the number of computations and output feature map size. Smaller strides lead to more\n",
        "overlapping regions, increasing computation, while larger strides reduce resolution and may skip\n",
        "fine details.\n",
        "\n",
        "Question 5: Compare and contrast different CNN-based architectures like\n",
        "LeNet, AlexNet, and VGG in terms of depth, filter sizes, and performance.\n",
        "\n",
        "Answer : LeNet (1990s): Shallow network with ~5 layers, small filters (5x5), designed for digit recognition\n",
        "(MNIST). AlexNet (2012): Deeper (8 layers), larger filters initially (11x11), uses ReLU, dropout, and\n",
        "GPU training, achieved breakthrough on ImageNet. VGG (2014): Very deep (16â€“19 layers),\n",
        "consistently uses 3x3 filters, improves feature extraction, but computationally expensive. In terms of\n",
        "performance, VGG > AlexNet > LeNet, with increasing depth and better generalization on large\n",
        "datasets.\n"
      ],
      "metadata": {
        "id": "NdOL_9k1pqFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question 6: Using keras, build and train a simple CNN model on the MNIST\n",
        "dataset from scratch.\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "# Build model\n",
        "model = Sequential([\n",
        "Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
        "MaxPooling2D((2,2)),\n",
        "Flatten(),\n",
        "Dense(128, activation='relu'),\n",
        "Dense(10, activation='softmax')\n",
        "])\n",
        "# Compile and train\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "5q5FjFZWqQ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question 7: Load and preprocess the CIFAR-10 dataset using Keras, and\n",
        "create a CNN model to classify RGB images.\n",
        "\"\"\"\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Load and preprocess\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train.astype('float32')/255.0, x_test.astype('float32')/255.0\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)\n",
        "# Model\n",
        "model = Sequential([\n",
        "Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "MaxPooling2D((2,2)),\n",
        "Conv2D(64, (3,3), activation='relu'),\n",
        "MaxPooling2D((2,2)),\n",
        "Flatten(),\n",
        "Dense(128, activation='relu'),\n",
        "Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n",
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "8YjdGMm1qcZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question 8: Using PyTorch, write a script to define and train a CNN on the\n",
        "MNIST dataset\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "# Data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "# Model\n",
        "class CNN(nn.Module):\n",
        "def __init__(self):\n",
        "super(CNN, self).__init__()\n",
        "self.conv1 = nn.Conv2d(1, 32, 3)\n",
        "self.pool = nn.MaxPool2d(2, 2)\n",
        "self.fc1 = nn.Linear(32*13*13, 128)\n",
        "self.fc2 = nn.Linear(128, 10)\n",
        "def forward(self, x):\n",
        "x = self.pool(torch.relu(self.conv1(x)))\n",
        "x = x.view(-1, 32*13*13)\n",
        "x = torch.relu(self.fc1(x))\n",
        "x = self.fc2(x)\n",
        "return x\n",
        "model = CNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Training\n",
        "for epoch in range(5):\n",
        "for images, labels in train_loader:\n",
        "optimizer.zero_grad()\n",
        "outputs = model(images)\n",
        "loss = criterion(outputs, labels)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "# Evaluation\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "for images, labels in test_loader:\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "total += labels.size(0)\n",
        "correct += (predicted == labels).sum().item()\n",
        "print('Test Accuracy:', 100 * correct / total)"
      ],
      "metadata": {
        "id": "SKd84fOSqoJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question 9: Given a custom image dataset stored in a local directory, write\n",
        "code using Keras ImageDataGenerator to preprocess and train a CNN model.\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "# Image data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_gen = train_datagen.flow_from_directory('data/train', target_size=(64,64), batch_size=32, class_val_gen = train_datagen.flow_from_directory('data/train', target_size=(64,64), batch_size=32, class_mode='# CNN model\n",
        "model = Sequential([\n",
        "Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
        "MaxPooling2D((2,2)),\n",
        "Flatten(),\n",
        "Dense(128, activation='relu'),\n",
        "Dense(train_gen.num_classes, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_gen, validation_data=val_gen, epochs=10)\n"
      ],
      "metadata": {
        "id": "LQN-BsnDqwVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Question 10: End-to-end approach for building and deploying a CNN model\n",
        "for classifying chest X-ray images into Normal and Pneumonia.\n",
        "\"\"\"\n",
        "\n",
        "#1. Data Preparation: Collect and organize chest X-ray images into train, validation, and test folders.\n",
        "#2. Model Training: Build a CNN with convolutional and pooling layers, followed by dense layers with softmax\n",
        "#3. Evaluation: Evaluate performance using accuracy, precision, recall, and confusion matrix.\n",
        "#4. Deployment: Save the trained model. Use Streamlit to build a simple web interface where users can Example Streamlit code:\n",
        "import streamlit as st\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "model = load_model('xray_model.h5')\n",
        "st.title('Chest X-Ray Classifier')\n",
        "uploaded_file = st.file_uploader('Upload Chest X-ray')\n",
        "if uploaded_file:\n",
        "img = image.load_img(uploaded_file, target_size=(224,224))\n",
        "img_array = image.img_to_array(img)/255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "prediction = model.predict(img_array)\n",
        "st.write('Prediction:', 'Normal' if prediction[0][0] > 0.5 else 'Pneumonia')"
      ],
      "metadata": {
        "id": "Y8r4BoTSq6BY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
