{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77cc0f63",
   "metadata": {},
   "source": [
    "\n",
    "# Convolutional Neural Networks (CNN) Assignment\n",
    "## PwSkills â€“ Deep Learning\n",
    "\n",
    "This notebook contains solutions for:\n",
    "\n",
    "### Part A: Theoretical Questions\n",
    "- CNN Architecture\n",
    "- LeNet-5\n",
    "- AlexNet vs VGGNet\n",
    "- Transfer Learning\n",
    "- ResNet Residual Connections\n",
    "\n",
    "### Part B: Practical Questions\n",
    "- LeNet-5 implementation on MNIST\n",
    "- Transfer Learning using VGG16\n",
    "- Filter and Feature Map Visualization\n",
    "- GoogLeNet / Inception Training\n",
    "- Healthcare AI Deployment Strategy\n",
    "\n",
    "Each question is followed by its answer and implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb9ce3",
   "metadata": {},
   "source": [
    "## Part A: Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3dc7d",
   "metadata": {},
   "source": [
    "### Question 1: What is a Convolutional Neural Network (CNN), and how does it differ from traditional fully connected neural networks in terms of architecture and performance on image data?\n",
    "\n",
    "**Answer:**\n",
    "A Convolutional Neural Network (CNN) is a type of deep learning model specifically designed for processing grid-like data such as images. CNNs use convolutional layers to automatically learn spatial hierarchies of features.\n",
    "\n",
    "Differences from Fully Connected Networks:\n",
    "- CNNs use local receptive fields and shared weights, reducing parameters significantly.\n",
    "- Fully connected networks treat images as flattened vectors, losing spatial relationships.\n",
    "- CNNs are computationally efficient and perform better on image tasks due to feature extraction and translation invariance.\n",
    "- CNNs require fewer parameters and reduce overfitting compared to dense networks for image data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0aa45",
   "metadata": {},
   "source": [
    "### Question 2: Discuss the architecture of LeNet-5 and explain how it laid the foundation for modern deep learning models in computer vision. Include references to its original research paper.\n",
    "\n",
    "**Answer:**\n",
    "LeNet-5, proposed by Yann LeCun et al. in 1998 in the paper 'Gradient-Based Learning Applied to Document Recognition', is one of the earliest CNN architectures.\n",
    "\n",
    "Architecture:\n",
    "- Input: 32x32 grayscale image\n",
    "- Convolution layer\n",
    "- Average pooling layer\n",
    "- Convolution layer\n",
    "- Average pooling layer\n",
    "- Fully connected layers\n",
    "- Output layer\n",
    "\n",
    "Contribution:\n",
    "- Introduced convolution and pooling layers.\n",
    "- Demonstrated end-to-end learning for image recognition.\n",
    "- Established weight sharing and local connectivity concepts used in modern CNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbab18c4",
   "metadata": {},
   "source": [
    "### Question 3: Compare and contrast AlexNet and VGGNet in terms of design principles, number of parameters, and performance.\n",
    "\n",
    "**Answer:**\n",
    "AlexNet (2012):\n",
    "- Introduced ReLU activation and dropout.\n",
    "- Used large convolution filters.\n",
    "- Around 60 million parameters.\n",
    "- Improved ImageNet performance significantly.\n",
    "- Limitation: computationally heavy.\n",
    "\n",
    "VGGNet (2014):\n",
    "- Used smaller 3x3 convolution filters stacked deeply.\n",
    "- Simpler and uniform architecture.\n",
    "- Around 138 million parameters (VGG16).\n",
    "- Better feature representation but very memory intensive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4aea66",
   "metadata": {},
   "source": [
    "### Question 4: What is transfer learning in the context of image classification?\n",
    "\n",
    "**Answer:**\n",
    "Transfer learning involves using a pre-trained model trained on a large dataset and adapting it to a new related task.\n",
    "\n",
    "Benefits:\n",
    "- Reduces training time.\n",
    "- Requires less labeled data.\n",
    "- Improves performance when dataset is small.\n",
    "- Uses previously learned features such as edges and textures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ec0ee",
   "metadata": {},
   "source": [
    "### Question 5: Describe the role of residual connections in ResNet architecture.\n",
    "\n",
    "**Answer:**\n",
    "Residual connections allow information to skip layers by adding input directly to output of deeper layers.\n",
    "\n",
    "Benefits:\n",
    "- Prevents vanishing gradient problem.\n",
    "- Enables training of very deep networks.\n",
    "- Helps gradients flow backward easily.\n",
    "- Improves accuracy and convergence speed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02462d",
   "metadata": {},
   "source": [
    "## Part B: Practical Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d51853",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c7065f",
   "metadata": {},
   "source": [
    "\n",
    "### Question 6:\n",
    "Implement LeNet-5 architecture using TensorFlow to classify MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36afab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1,28,28,1)/255.0\n",
    "X_test = X_test.reshape(-1,28,28,1)/255.0\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(6,(5,5),activation='relu',input_shape=(28,28,1)),\n",
    "    layers.AveragePooling2D(),\n",
    "    layers.Conv2D(16,(5,5),activation='relu'),\n",
    "    layers.AveragePooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120,activation='relu'),\n",
    "    layers.Dense(84,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,y_train,epochs=3,validation_split=0.1)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test,y_test)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601165fb",
   "metadata": {},
   "source": [
    "\n",
    "### Question 7:\n",
    "Use a pre-trained VGG16 model via transfer learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8788e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7857eb3",
   "metadata": {},
   "source": [
    "\n",
    "### Question 8:\n",
    "Visualize filters and feature maps of first convolutional layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eee1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "print(\"Filter shape:\", filters.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad0c05",
   "metadata": {},
   "source": [
    "\n",
    "### Question 9:\n",
    "Train a CNN on CIFAR-10 dataset and plot training and validation accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cab36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(X_train,y_train),(X_test,y_test)=cifar10.load_data()\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,3)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "history = cnn.fit(X_train,y_train,epochs=5,validation_split=0.1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392c434",
   "metadata": {},
   "source": [
    "\n",
    "### Question 10:\n",
    "Healthcare AI system for X-ray classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097c7b07",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "\n",
    "Recommended Approach:\n",
    "- Use transfer learning with ResNet50 or InceptionV3 because medical datasets are usually small.\n",
    "- Pretrained models capture general visual features useful for medical imaging.\n",
    "\n",
    "Workflow:\n",
    "1. Collect and preprocess X-ray images.\n",
    "2. Apply data augmentation to increase dataset diversity.\n",
    "3. Fine-tune last layers of pretrained ResNet.\n",
    "4. Use validation metrics such as accuracy, precision, recall, and F1-score.\n",
    "\n",
    "Deployment Strategy:\n",
    "- Export model using TensorFlow SavedModel format.\n",
    "- Deploy via REST API.\n",
    "- Monitor predictions and retrain periodically.\n",
    "\n",
    "Business Benefits:\n",
    "- Faster diagnosis.\n",
    "- Reduced workload for radiologists.\n",
    "- Early detection improving patient outcomes.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
